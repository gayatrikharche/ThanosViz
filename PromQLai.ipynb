{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BSFQbsMlJRXf",
        "outputId": "9bedd05f-bc4c-4b21-e8a8-9c9466442e0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting litellm\n",
            "  Downloading litellm-1.63.12-py3-none-any.whl.metadata (36 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from litellm) (3.11.13)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from litellm) (8.1.8)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (0.28.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.8.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (8.6.1)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from litellm) (3.1.6)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (4.23.0)\n",
            "Collecting openai>=1.66.1 (from litellm)\n",
            "  Downloading openai-1.66.5-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from litellm) (2.10.6)\n",
            "Collecting python-dotenv>=0.2.0 (from litellm)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting tiktoken>=0.7.0 (from litellm)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from litellm) (0.21.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->litellm) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->litellm) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=6.8.0->litellm) (3.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2<4.0.0,>=3.1.2->litellm) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema<5.0.0,>=4.22.0->litellm) (0.23.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.1->litellm) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.1->litellm) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.1->litellm) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.1->litellm) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai>=1.66.1->litellm) (4.12.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.0.0->litellm) (2.27.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken>=0.7.0->litellm) (2.32.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (1.3.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (0.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->litellm) (1.18.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from tokenizers->litellm) (0.28.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (3.17.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers->litellm) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken>=0.7.0->litellm) (2.3.0)\n",
            "Downloading litellm-1.63.12-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.66.5-py3-none-any.whl (571 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.1/571.1 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-dotenv, tiktoken, openai, litellm\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.61.1\n",
            "    Uninstalling openai-1.61.1:\n",
            "      Successfully uninstalled openai-1.61.1\n",
            "Successfully installed litellm-1.63.12 openai-1.66.5 python-dotenv-1.0.1 tiktoken-0.9.0\n"
          ]
        }
      ],
      "source": [
        "pip install litellm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import requests\n",
        "import re\n",
        "import json\n",
        "from prometheus_api_client import PrometheusConnect\n",
        "import datetime"
      ],
      "metadata": {
        "id": "aTRP1_aSJTuB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "client = openai.OpenAI(\n",
        "    api_key=\"sk-1FFVoBIt19PHRs4OYcDcnA\",\n",
        "    base_url=\"https://llm.nrp-nautilus.io\" # LiteLLM Proxy is OpenAI compatible, Read More: https://docs.litellm.ai/docs/proxy/user_keys\n",
        ")"
      ],
      "metadata": {
        "id": "j08dTPSqJUO1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt1 = \"\"\"\n",
        "You are an expert in monitoring and observability, specializing in Thanos and Prometheus. Your task is to generate valid PromQL (Prometheus Query Language) queries for Thanos based on user requests. Follow these guidelines:\n",
        "\n",
        "1. **Understand the Request**:\n",
        "   - The user will describe the metric or data they want to query (e.g., CPU usage, HTTP requests, target status).\n",
        "   - Identify the metric name and any relevant labels (e.g., `job`, `instance`).\n",
        "   - Check what is asked hour, minutes, months, etc.\n",
        "\n",
        "2. **Generate PromQL Queries**:\n",
        "   - Use PromQL syntax to create the query.\n",
        "   - For calculating total usage over time, use the sum_over_time() function.\n",
        "   - For time-series data, use functions like rate(), sum(), or avg() as needed.\n",
        "   - For instant queries, return the current value of the metric.\n",
        "   - For range queries, specify the time range using [time] (e.g., [5m] for the last 5 minutes).\n",
        "   - Use correct metrics name.\n",
        "\n",
        "3. **Examples**:\n",
        "   - User: \"Get the HTTP request rate over the last 5 minutes.\"\n",
        "     Query: rate(http_requests_total[5m]\n",
        "   - User: \"Check if all targets are up.\"\n",
        "     Query: up\n",
        "   - User: \"Get the total memory usage for a specific job.\"\n",
        "     Query: sum(memory_usage{job=\"my-service\"})\n",
        "   - User: \"Calculate the total GPU usage over the past year, aggregated at 1-hour intervals.\"\n",
        "     Query: sum_over_time(namespace_gpu_usage[1y:1h])\n",
        "\n",
        "4. **Clarify Ambiguities**:\n",
        "   - If the user's request is unclear, ask for clarification (e.g., \"Which job or instance are you interested in?\").\n",
        "\n",
        "5. **Output**:\n",
        "   - Return only the PromQL query, no inverted commas.\n",
        "   - Do not include explanations unless explicitly asked.\n",
        "\n",
        "Now, generate a query based on the user's request.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "5sY3XlcsJWDe"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Define the user's request\n",
        "# user_prompt1 = \"a scatter plot that visualizes CPU vs. GPU usage per namespace over the last year\"\n",
        "user_prompt1 = \"\"\"\n",
        "Get GPU usage over last month in an hour interval. And use a scatter plot to visualize it over time.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ElY--A8IJZnX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_promql_query(user_prompt, system_prompt):\n",
        "    \"\"\"\n",
        "    Generate a PromQL query using the AI agent.\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "    model=\"llama3\", # model to send to the proxy\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": system_prompt\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",  # User's request\n",
        "            \"content\": user_prompt\n",
        "        }\n",
        "    ])\n",
        "    prompt_query = response.choices[0].message.content\n",
        "    return prompt_query\n",
        "\n",
        "queries = generate_promql_query(user_prompt1, system_prompt1)\n"
      ],
      "metadata": {
        "id": "RThc4E-gJens"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(queries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdTv-ZicJmqh",
        "outputId": "636010cc-d28a-45c5-e462-13045d623b5b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sum_over_time(namespace_gpu_usage[30d:1h])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CwUK9C1W2sIx",
        "outputId": "a21b2920-cc5a-4379-dfdf-a0b514f6f7c3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sum_over_time(namespace_gpu_usage[30d:1h])'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zCgzvg5NPKqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "def fetch_data(query):\n",
        "\n",
        "  url = \"https://thanos.nrp-nautilus.io/api/v1/query\"\n",
        "\n",
        "  # Send the GET request\n",
        "  response = requests.get(url, params={'query': query})\n",
        "  data = response.json()\n",
        "  return data\n",
        "  # # Check if the request was successful (status code 200)\n",
        "  # if response.status_code == 200:\n",
        "  #     data = response.json()\n",
        "  #     print(data)\n",
        "  # else:\n",
        "  #     print(f\"Error fetching data: {response.status_code}\")\n",
        "\n",
        "llm1_data = fetch_data(queries)"
      ],
      "metadata": {
        "id": "44e1Z9DJQN4f"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm1_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRio0BGkcyDj",
        "outputId": "b6b265cd-0d0c-42a7-ac76-bceef38dfdc6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'success',\n",
              " 'data': {'resultType': 'vector',\n",
              "  'result': [{'metric': {'namespace': '1-ashesh-tacs-lab',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '45']},\n",
              "   {'metric': {'namespace': '1yehudabock-ml', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '103']},\n",
              "   {'metric': {'namespace': 'a-cloninger', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '672']},\n",
              "   {'metric': {'namespace': 'act-lab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '6']},\n",
              "   {'metric': {'namespace': 'ai-fusion-ga', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '5239']},\n",
              "   {'metric': {'namespace': 'ai-md', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '8']},\n",
              "   {'metric': {'namespace': 'ai-schmidt', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '741']},\n",
              "   {'metric': {'namespace': 'aiea-auditors', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2061']},\n",
              "   {'metric': {'namespace': 'aiea-interns', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '434']},\n",
              "   {'metric': {'namespace': 'aiea-slugbotics', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '897']},\n",
              "   {'metric': {'namespace': 'alonlab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '170']},\n",
              "   {'metric': {'namespace': 'amnh-herpetology-ddebaun',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '260']},\n",
              "   {'metric': {'namespace': 'amnh-jupyterhub', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '720']},\n",
              "   {'metric': {'namespace': 'anthony-lab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '731']},\n",
              "   {'metric': {'namespace': 'aoi-lab-scratch', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '909']},\n",
              "   {'metric': {'namespace': 'ardagroup', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '476']},\n",
              "   {'metric': {'namespace': 'aryalab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1801']},\n",
              "   {'metric': {'namespace': 'assel', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '3484']},\n",
              "   {'metric': {'namespace': 'autoslug', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '33']},\n",
              "   {'metric': {'namespace': 'axol1tl', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '397']},\n",
              "   {'metric': {'namespace': 'bak-staff-lab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2']},\n",
              "   {'metric': {'namespace': 'bbhnet', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '9754']},\n",
              "   {'metric': {'namespace': 'binderhub-ssl', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '8']},\n",
              "   {'metric': {'namespace': 'biocore-build', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '26']},\n",
              "   {'metric': {'namespace': 'biodiversity', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '189']},\n",
              "   {'metric': {'namespace': 'bmebootcamp', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2']},\n",
              "   {'metric': {'namespace': 'braingeneers', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '3797']},\n",
              "   {'metric': {'namespace': 'cal-poly-humboldt-jupyter-instruction1',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '3']},\n",
              "   {'metric': {'namespace': 'cal-poly-humboldt-microglia',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '211']},\n",
              "   {'metric': {'namespace': 'cal-poly-humboldt-rl-experiment',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '45']},\n",
              "   {'metric': {'namespace': 'calab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '823']},\n",
              "   {'metric': {'namespace': 'cdss-discovery-prod',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '47']},\n",
              "   {'metric': {'namespace': 'cdss-discovery-staging',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '14']},\n",
              "   {'metric': {'namespace': 'choderalab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '36496']},\n",
              "   {'metric': {'namespace': 'chronic-opioid-lab',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '7068']},\n",
              "   {'metric': {'namespace': 'climate-analytics',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '6052']},\n",
              "   {'metric': {'namespace': 'cls-imagenet', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '7']},\n",
              "   {'metric': {'namespace': 'cms-ml', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '10489']},\n",
              "   {'metric': {'namespace': 'coder', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '4989']},\n",
              "   {'metric': {'namespace': 'cogrob', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '48210']},\n",
              "   {'metric': {'namespace': 'compression', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '3613']},\n",
              "   {'metric': {'namespace': 'coop-perc', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '418']},\n",
              "   {'metric': {'namespace': 'csu-tide-jupyterhub',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '4119']},\n",
              "   {'metric': {'namespace': 'csuf-cpsc531-hadoop-test',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1422']},\n",
              "   {'metric': {'namespace': 'csuf-poc', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '164']},\n",
              "   {'metric': {'namespace': 'csuf-titans', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '4497']},\n",
              "   {'metric': {'namespace': 'csufresno-johnwa',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '675']},\n",
              "   {'metric': {'namespace': 'csun-deep-learning',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1507']},\n",
              "   {'metric': {'namespace': 'csun-edl', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '720']},\n",
              "   {'metric': {'namespace': 'csusb-ai', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '5']},\n",
              "   {'metric': {'namespace': 'csusb-chaseci', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2562']},\n",
              "   {'metric': {'namespace': 'csusb-hpc', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2962']},\n",
              "   {'metric': {'namespace': 'csusb-hub-dev', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2']},\n",
              "   {'metric': {'namespace': 'csusb-jupyterhub',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '100']},\n",
              "   {'metric': {'namespace': 'csusb-khan', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '720']},\n",
              "   {'metric': {'namespace': 'cyberarch', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '535']},\n",
              "   {'metric': {'namespace': 'dcct', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1339']},\n",
              "   {'metric': {'namespace': 'deep-forecast', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2896']},\n",
              "   {'metric': {'namespace': 'designlab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '41']},\n",
              "   {'metric': {'namespace': 'digits', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '3343']},\n",
              "   {'metric': {'namespace': 'dimm', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '15']},\n",
              "   {'metric': {'namespace': 'dl4nlpspace', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '10836']},\n",
              "   {'metric': {'namespace': 'dwang', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1954']},\n",
              "   {'metric': {'namespace': 'ecdna', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2292']},\n",
              "   {'metric': {'namespace': 'ece-scisrs', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '4']},\n",
              "   {'metric': {'namespace': 'ece-tarajavidi', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '157']},\n",
              "   {'metric': {'namespace': 'ece3d-vision', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1083']},\n",
              "   {'metric': {'namespace': 'ecepxie', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '4613']},\n",
              "   {'metric': {'namespace': 'ecewcsng', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '4098']},\n",
              "   {'metric': {'namespace': 'ehf', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2089']},\n",
              "   {'metric': {'namespace': 'engr131spring', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '720']},\n",
              "   {'metric': {'namespace': 'environmental-analytics-group-usra',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2410']},\n",
              "   {'metric': {'namespace': 'erl-ucsd', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '804']},\n",
              "   {'metric': {'namespace': 'erl-ucsd-supp', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '551']},\n",
              "   {'metric': {'namespace': 'espm-157', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '7010']},\n",
              "   {'metric': {'namespace': 'evl', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1011']},\n",
              "   {'metric': {'namespace': 'eyetracking', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1222']},\n",
              "   {'metric': {'namespace': 'fusion-psfc', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '281']},\n",
              "   {'metric': {'namespace': 'gai-lina-group', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '78']},\n",
              "   {'metric': {'namespace': 'genai-lab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '71966']},\n",
              "   {'metric': {'namespace': 'gilpin-lab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2772']},\n",
              "   {'metric': {'namespace': 'gp-engine-malof', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1697']},\n",
              "   {'metric': {'namespace': 'gp-engine-mizzou-blab',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '333']},\n",
              "   {'metric': {'namespace': 'gp-engine-mizzou-hpdi-pretrain',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '4916']},\n",
              "   {'metric': {'namespace': 'gp-engine-mizzou-mindful',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '6']},\n",
              "   {'metric': {'namespace': 'gp-engine-mst-awuah',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '13']},\n",
              "   {'metric': {'namespace': 'gp-engine-research-jhub',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '5']},\n",
              "   {'metric': {'namespace': 'gp-engine-unoselab02',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '422']},\n",
              "   {'metric': {'namespace': 'gpn-mizzou-bml', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '587']},\n",
              "   {'metric': {'namespace': 'gpn-mizzou-hpc', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '657']},\n",
              "   {'metric': {'namespace': 'gpn-mizzou-hpdi', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '23']},\n",
              "   {'metric': {'namespace': 'gpn-mizzou-kaziclab',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '40']},\n",
              "   {'metric': {'namespace': 'gpn-mizzou-muem', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1158']},\n",
              "   {'metric': {'namespace': 'gpn-mizzou-sgs', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '4009']},\n",
              "   {'metric': {'namespace': 'gpn-mizzou-sknnh',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '720']},\n",
              "   {'metric': {'namespace': 'gpn-mizzou-vigir',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '9855']},\n",
              "   {'metric': {'namespace': 'gpn-mizzou-vigir-gpu',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1853']},\n",
              "   {'metric': {'namespace': 'gpu-mon', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '373403']},\n",
              "   {'metric': {'namespace': 'graphnlp', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '984']},\n",
              "   {'metric': {'namespace': 'guru-research', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1095']},\n",
              "   {'metric': {'namespace': 'hengenlab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '28']},\n",
              "   {'metric': {'namespace': 'hls4ml-drexel', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '759']},\n",
              "   {'metric': {'namespace': 'i2-danswer', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '36']},\n",
              "   {'metric': {'namespace': 'icecube-ml', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '5086']},\n",
              "   {'metric': {'namespace': 'inst-eecs-berkeley',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1']},\n",
              "   {'metric': {'namespace': 'isaac-sim', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '206']},\n",
              "   {'metric': {'namespace': 'isfiligoi', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1']},\n",
              "   {'metric': {'namespace': 'jkb-lab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '720']},\n",
              "   {'metric': {'namespace': 'jlab-nlp', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '15924']},\n",
              "   {'metric': {'namespace': 'juice', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1440']},\n",
              "   {'metric': {'namespace': 'jupyterlab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '16211']},\n",
              "   {'metric': {'namespace': 'jupyterlab-east', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '28']},\n",
              "   {'metric': {'namespace': 'knightlab-ml', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '200']},\n",
              "   {'metric': {'namespace': 'krg-maestro', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '550']},\n",
              "   {'metric': {'namespace': 'kundajelab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '26246']},\n",
              "   {'metric': {'namespace': 'lemn-lab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '49']},\n",
              "   {'metric': {'namespace': 'librareome', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '720']},\n",
              "   {'metric': {'namespace': 'mfsada', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '311']},\n",
              "   {'metric': {'namespace': 'mishne-lab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '9142']},\n",
              "   {'metric': {'namespace': 'mizzou', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '185']},\n",
              "   {'metric': {'namespace': 'ml-imagination', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1369']},\n",
              "   {'metric': {'namespace': 'mrat-project', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '773']},\n",
              "   {'metric': {'namespace': 'ncgassel', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '5577']},\n",
              "   {'metric': {'namespace': 'ndp', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '268']},\n",
              "   {'metric': {'namespace': 'nicest-ychen', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '367']},\n",
              "   {'metric': {'namespace': 'niddk', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1161']},\n",
              "   {'metric': {'namespace': 'nlpapps', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '109']},\n",
              "   {'metric': {'namespace': 'nlplab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '220']},\n",
              "   {'metric': {'namespace': 'noise-prompt', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '3456']},\n",
              "   {'metric': {'namespace': 'nourish-sdsc', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '916']},\n",
              "   {'metric': {'namespace': 'nrp-llm', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '9278']},\n",
              "   {'metric': {'namespace': 'nrp-u55c', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1']},\n",
              "   {'metric': {'namespace': 'nsf-maica', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '8296']},\n",
              "   {'metric': {'namespace': 'nsf-reu', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '720']},\n",
              "   {'metric': {'namespace': 'okstate-it-kb-analysis',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '7']},\n",
              "   {'metric': {'namespace': 'openforcefield', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1493']},\n",
              "   {'metric': {'namespace': 'osg-icecube', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '30464']},\n",
              "   {'metric': {'namespace': 'osg-ligo', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '32410']},\n",
              "   {'metric': {'namespace': 'osg-nrao', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '419']},\n",
              "   {'metric': {'namespace': 'pa-riemann', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2823']},\n",
              "   {'metric': {'namespace': 'pgml', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '233']},\n",
              "   {'metric': {'namespace': 'phillpsen', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2492']},\n",
              "   {'metric': {'namespace': 'pratik-doshi-research',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '505']},\n",
              "   {'metric': {'namespace': 'prism-fpga-caching',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '93']},\n",
              "   {'metric': {'namespace': 'prism-jupyterlab',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '75']},\n",
              "   {'metric': {'namespace': 'progsa', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '76']},\n",
              "   {'metric': {'namespace': 'project1asu', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2']},\n",
              "   {'metric': {'namespace': 'quick-qm', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '106']},\n",
              "   {'metric': {'namespace': 'r2-lab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2777']},\n",
              "   {'metric': {'namespace': 'razvanlab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '6148']},\n",
              "   {'metric': {'namespace': 'real-ucsc', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '16']},\n",
              "   {'metric': {'namespace': 'rl-dev', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '3660']},\n",
              "   {'metric': {'namespace': 'rl-multitask', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '768']},\n",
              "   {'metric': {'namespace': 'rl-work', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1130']},\n",
              "   {'metric': {'namespace': 'rse-kube', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '720']},\n",
              "   {'metric': {'namespace': 'scb-usra', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '5']},\n",
              "   {'metric': {'namespace': 'sdccd-jupyterhub-prod',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2398']},\n",
              "   {'metric': {'namespace': 'sdsc-llm', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '10380']},\n",
              "   {'metric': {'namespace': 'sdsu-aicenter', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '988']},\n",
              "   {'metric': {'namespace': 'sdsu-goldberg', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '720']},\n",
              "   {'metric': {'namespace': 'sdsu-jupyterhub', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '4339']},\n",
              "   {'metric': {'namespace': 'sdsu-llm', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2160']},\n",
              "   {'metric': {'namespace': 'sdsu-rci-jh', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '16775']},\n",
              "   {'metric': {'namespace': 'sdsu-rci-jh-dev', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '102']},\n",
              "   {'metric': {'namespace': 'sdsu-shen-climate-lab',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1026']},\n",
              "   {'metric': {'namespace': 'sdsu-smile', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '932']},\n",
              "   {'metric': {'namespace': 'sdsu-tend-lab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '239']},\n",
              "   {'metric': {'namespace': 'seelab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2979']},\n",
              "   {'metric': {'namespace': 'seelab-profiling',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '459']},\n",
              "   {'metric': {'namespace': 'segmentation', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '730']},\n",
              "   {'metric': {'namespace': 'self-supervised-video',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '808']},\n",
              "   {'metric': {'namespace': 'selkies-vish', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '73']},\n",
              "   {'metric': {'namespace': 'sgeiger', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '88']},\n",
              "   {'metric': {'namespace': 'shanxiaojun', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '969']},\n",
              "   {'metric': {'namespace': 'sigml', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '451']},\n",
              "   {'metric': {'namespace': 'soledad', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '30']},\n",
              "   {'metric': {'namespace': 'sonic-server', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1183']},\n",
              "   {'metric': {'namespace': 'spatiotemporal-decision-making',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '70']},\n",
              "   {'metric': {'namespace': 'srinjoy-keras', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1334']},\n",
              "   {'metric': {'namespace': 'srip22-ctl', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '345']},\n",
              "   {'metric': {'namespace': 'srip23-nerf', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2085']},\n",
              "   {'metric': {'namespace': 'svcl-amodal', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '382']},\n",
              "   {'metric': {'namespace': 'svcl-clip', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '409']},\n",
              "   {'metric': {'namespace': 'svcl-emotion', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '112']},\n",
              "   {'metric': {'namespace': 'svcl-handpose', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '85']},\n",
              "   {'metric': {'namespace': 'svcl-video', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '81']},\n",
              "   {'metric': {'namespace': 'svcl-vit', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '17017']},\n",
              "   {'metric': {'namespace': 'svcl-vlm', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2391']},\n",
              "   {'metric': {'namespace': 'syndromic-logger',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '571']},\n",
              "   {'metric': {'namespace': 'system-test', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '6']},\n",
              "   {'metric': {'namespace': 'tempredict', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '84']},\n",
              "   {'metric': {'namespace': 'triton', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1700']},\n",
              "   {'metric': {'namespace': 'ucsb-cms-ml', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '1187']},\n",
              "   {'metric': {'namespace': 'ucsb-csc-jupyterhub',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '2']},\n",
              "   {'metric': {'namespace': 'ucsb-moehlis', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '50']},\n",
              "   {'metric': {'namespace': 'ucsb-opus-lab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '207']},\n",
              "   {'metric': {'namespace': 'ucsc-hsc', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '63']},\n",
              "   {'metric': {'namespace': 'ucsc-jupyter-hub',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '720']},\n",
              "   {'metric': {'namespace': 'ucsc-vizlab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '436']},\n",
              "   {'metric': {'namespace': 'ucsd-haosulab', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '50827']},\n",
              "   {'metric': {'namespace': 'ucsd-ravigroup', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '11185']},\n",
              "   {'metric': {'namespace': 'unl-weitzel', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '330']},\n",
              "   {'metric': {'namespace': 'uw-a3d3', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '79']},\n",
              "   {'metric': {'namespace': 'wenglab-interpretable-ai',\n",
              "     'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '179']},\n",
              "   {'metric': {'namespace': 'yelan-neuro', 'prometheus': 'monitoring/k8s'},\n",
              "    'value': [1742415156.228, '14952']}],\n",
              "  'analysis': {}}}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# system_prompt2= \"\"\"You are an expert in data visualization. Your task is to a generate plots based on time-series data fetched from Thanos. Follow these guidelines:\n",
        "\n",
        "# 1. **Understand the Data**:\n",
        "#    - The data consists of timestamps and corresponding values for a specific metric.\n",
        "#    - The metric name and time range are provided.\n",
        "\n",
        "# 2. **Generate Plots**:\n",
        "#    - Use a plotting library (e.g., Matplotlib, Plotly) to visualize the data.\n",
        "#    - For time-series data, create a line plot with timestamps on the x-axis and values on the y-axis.\n",
        "#    - Add titles, labels, and grid lines for clarity.\n",
        "\n",
        "# 3. **Examples**:\n",
        "#    - Metric: `cpu_usage`, Time Range: `5m`\n",
        "#      Plot: A line plot showing CPU usage over the last 5 minutes.\n",
        "#    - Metric: `http_requests_total`, Time Range: `1h`\n",
        "#      Plot: A line plot showing HTTP request rates over the last hour.\n",
        "\n",
        "# 4. **Output**:\n",
        "#    - Return the generated plot or a link to the visualization.\n",
        "\n",
        "# Now, generate a plot based on the provided data.\n",
        "# \"\"\"\n",
        "\n",
        "# system_prompt2 = \"\"\"\n",
        "#     You are a data visualization expert. Your task is to generate Python code to plot the fetched data. Follow these rules:\n",
        "#     4. Use different colors.\n",
        "#     5. Add proper labels, titles, and grid lines.\n",
        "#     6. Return only the Python code as a string, without any explanations, markdown formatting, or additional text so that I can use exec() on the output and run directly in my notebook.\n",
        "#     \"\"\"\n",
        "\n",
        "plot_prompt_template = \"\"\"\n",
        "Given the following data and user request, generate an appropriate plot.\n",
        "\n",
        "User Request: \"{user_request}\"\n",
        "\n",
        "Fetched Data (JSON format):\n",
        "{fetched_data}\n",
        "\n",
        "Instructions:\n",
        "1. Parse the fetched data and convert timestamps into a readable format (e.g., datetime).\n",
        "2. Choose the appropriate plot type based on the user request (e.g., scatter, line, bar).\n",
        "3. Generate the plot using Matplotlib, Seaborn, or Plotly.\n",
        "4. Return a Python script that processes the data and creates the requested visualization.\n",
        "5. Return only the Python code as a string, without any comments, explanations, markdown formatting, or additional text.\n",
        "6. Do not write python comments starting with \"#\" or \"'''\".\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "LJW92pO_Thp5"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the system prompt\n",
        "system_prompt2 = plot_prompt_template.format(user_request= user_prompt1, fetched_data=llm1_data)\n"
      ],
      "metadata": {
        "id": "w2Rs0SKuThnk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(system_prompt2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcsumHatfb8t",
        "outputId": "780b8e6e-b0e5-4f04-c09e-5c6c26c2e208"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fetched_data_str = json.dumps(llm1_data, indent=4)"
      ],
      "metadata": {
        "id": "0_Am78utfoUZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_plot_code(user_prompt, system_prompt):\n",
        "    \"\"\"\n",
        "    Generate plots\n",
        "    \"\"\"\n",
        "    response = client.chat.completions.create(\n",
        "    model=\"llama3\", # model to send to the proxy\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": system_prompt\n",
        "        },\n",
        "        {\n",
        "            \"role\": \"user\",  # User's request\n",
        "            \"content\": user_prompt\n",
        "        }\n",
        "    ])\n",
        "    plot = response.choices[0].message.content\n",
        "    return plot\n",
        "\n",
        "plot_code = generate_plot_code(fetched_data_str, system_prompt2)\n"
      ],
      "metadata": {
        "id": "QQx2XJ3iThks"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "m-6ZvANNThiG",
        "outputId": "d48fe66d-00bd-49a1-91a7-f04d70d407d0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'```python\\nimport json\\nimport plotly.graph_objects as go\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\n\\ndef plot_gpu_usage(data):\\n    df = pd.json_normalize(data[\\'data\\'][\\'result\\'])\\n    df = df.rename(columns={\\'metric.namespace\\': \\'namespace\\', \\'value.0\\': \\'timestamp\\', \\'value.1\\': \\'gpu_usage\\'})\\n    df[\\'timestamp\\'] = pd.to_datetime(df[\\'timestamp\\'], unit=\\'s\\')\\n\\n    gpu_df = df.groupby(\\'namespace\\')[\\'gpu_usage\\'].sum().sort_values(ascending=False).head(20).reset_index()\\n    gpu_df = gpu_df.rename(columns={\\'namespace\\': \\'Namespace\\', \\'gpu_usage\\': \\'GPU Usage\\'})\\n\\n    fig = go.Figure(data=[go.Scatter(x=gpu_df[\\'Namespace\\'], y=gpu_df[\\'GPU Usage\\'], mode=\\'markers+lines\\')])\\n    fig.update_layout(title=\\'GPU Usage\\', xaxis_title=\\'Namespace\\', yaxis_title=\\'GPU Usage\\')\\n    fig.show()\\n\\n    # Alternatively, use matplotlib\\n    plt.figure(figsize=(10,6))\\n    plt.plot(gpu_df[\\'Namespace\\'], gpu_df[\\'GPU Usage\\'], marker=\\'o\\')\\n    plt.title(\\'GPU Usage\\')\\n    plt.xlabel(\\'Namespace\\')\\n    plt.ylabel(\\'GPU Usage\\')\\n    plt.xticks(rotation=90)\\n    plt.show()\\n\\n# Assuming the provided JSON is stored in the \\'data\\' variable\\nplot_gpu_usage(json.loads(\\'\\'\\'{\"status\": \"success\", \"data\": { \"resultType\": \"vector\", \"result\": [...]}\\'\\'\\'))\\n```'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_plot_code(plot_code):\n",
        "    \"\"\"Removes markdown-style code block indicators like ```python and ```\"\"\"\n",
        "    plot_code = plot_code.replace(\"```python\", \"\").replace(\"```\", \"\").strip()\n",
        "    return plot_code\n",
        "\n",
        "# Clean the generated code before saving or executing\n",
        "cleaned_plot_code = clean_plot_code(plot_code)\n"
      ],
      "metadata": {
        "id": "wONpAeohIEXJ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_plot_code(cleaned_plot_code, filename=\"generated_plot.py\"):\n",
        "    \"\"\"Saves the generated Python code to a file.\"\"\"\n",
        "    with open(filename, \"w\") as f:\n",
        "        f.write(cleaned_plot_code)\n",
        "\n",
        "# Save the generated code\n",
        "save_plot_code(cleaned_plot_code)\n"
      ],
      "metadata": {
        "id": "HQCiTNjlHblL"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import generated_plot  # Import the generated script as a module\n",
        "\n",
        "# If the function name is known (e.g., plot_gpu_usage)\n",
        "data = fetched_data  # Pass the actual data\n",
        "generated_plot.plot_gpu_usage(data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "collapsed": true,
        "id": "HwhDnEz_i8ne",
        "outputId": "20c6668d-c7b3-4d60-ce06-6339e9899bca"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "error",
          "ename": "JSONDecodeError",
          "evalue": "Expecting value: line 1 column 68 (char 67)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-90f6347e0417>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgenerated_plot\u001b[0m  \u001b[0;31m# Import the generated script as a module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# If the function name is known (e.g., plot_gpu_usage)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetched_data\u001b[0m  \u001b[0;31m# Pass the actual data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgenerated_plot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_gpu_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/generated_plot.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Assuming the provided JSON is stored in the 'data' variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mplot_gpu_usage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'''{\"status\": \"success\", \"data\": { \"resultType\": \"vector\", \"result\": [...]}'''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/lib/python3.11/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 68 (char 67)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(prom)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SB6sUU27PXTZ",
        "outputId": "f0b1e843-a766-4b27-abd3-0462727b7216"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on PrometheusConnect in module prometheus_api_client.prometheus_connect object:\n",
            "\n",
            "class PrometheusConnect(builtins.object)\n",
            " |  PrometheusConnect(url: str = 'http://127.0.0.1:9090', headers: dict = None, disable_ssl: bool = False, retry: urllib3.util.retry.Retry = None, auth: tuple = None, proxy: dict = None, session: requests.sessions.Session = None, timeout: int = None)\n",
            " |  \n",
            " |  A Class for collection of metrics from a Prometheus Host.\n",
            " |  \n",
            " |  :param url: (str) url for the prometheus host\n",
            " |  :param headers: (dict) A dictionary of http headers to be used to communicate with\n",
            " |      the host. Example: {\"Authorization\": \"bearer my_oauth_token_to_the_host\"}\n",
            " |  :param disable_ssl: (bool) If set to True, will disable ssl certificate verification\n",
            " |      for the http requests made to the prometheus host\n",
            " |  :param retry: (Retry) Retry adapter to retry on HTTP errors\n",
            " |  :param auth: (optional) Auth tuple to enable Basic/Digest/Custom HTTP Auth. See python\n",
            " |      requests library auth parameter for further explanation.\n",
            " |  :param proxy: (Optional) Proxies dictionary to enable connection through proxy.\n",
            " |      Example: {\"http_proxy\": \"<ip_address/hostname:port>\", \"https_proxy\": \"<ip_address/hostname:port>\"}\n",
            " |  :param session (Optional) Custom requests.Session to enable complex HTTP configuration\n",
            " |  :param timeout: (Optional) A timeout (in seconds) applied to all requests\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, url: str = 'http://127.0.0.1:9090', headers: dict = None, disable_ssl: bool = False, retry: urllib3.util.retry.Retry = None, auth: tuple = None, proxy: dict = None, session: requests.sessions.Session = None, timeout: int = None)\n",
            " |      Functions as a Constructor for the class PrometheusConnect.\n",
            " |  \n",
            " |  all_metrics(self, params: dict = None)\n",
            " |      Get the list of all the metrics that the prometheus host scrapes.\n",
            " |      \n",
            " |      :param params: (dict) Optional dictionary containing GET parameters to be\n",
            " |          sent along with the API request, such as \"time\"\n",
            " |      :returns: (list) A list of names of all the metrics available from the\n",
            " |          specified prometheus host\n",
            " |      :raises:\n",
            " |          (RequestException) Raises an exception in case of a connection error\n",
            " |          (PrometheusApiClientException) Raises in case of non 200 response status code\n",
            " |  \n",
            " |  check_prometheus_connection(self, params: dict = None) -> bool\n",
            " |      Check Promethus connection.\n",
            " |      \n",
            " |      :param params: (dict) Optional dictionary containing parameters to be\n",
            " |          sent along with the API request.\n",
            " |      :returns: (bool) True if the endpoint can be reached, False if cannot be reached.\n",
            " |  \n",
            " |  custom_query(self, query: str, params: dict = None, timeout: int = None)\n",
            " |      Send a custom query to a Prometheus Host.\n",
            " |      \n",
            " |      This method takes as input a string which will be sent as a query to\n",
            " |      the specified Prometheus Host. This query is a PromQL query.\n",
            " |      \n",
            " |      :param query: (str) This is a PromQL query, a few examples can be found\n",
            " |          at https://prometheus.io/docs/prometheus/latest/querying/examples/\n",
            " |      :param params: (dict) Optional dictionary containing GET parameters to be\n",
            " |          sent along with the API request, such as \"time\"\n",
            " |      :param timeout: (Optional) A timeout (in seconds) applied to the request\n",
            " |      :returns: (list) A list of metric data received in response of the query sent\n",
            " |      :raises:\n",
            " |          (RequestException) Raises an exception in case of a connection error\n",
            " |          (PrometheusApiClientException) Raises in case of non 200 response status code\n",
            " |  \n",
            " |  custom_query_range(self, query: str, start_time: datetime.datetime, end_time: datetime.datetime, step: str, params: dict = None, timeout: int = None)\n",
            " |      Send a query_range to a Prometheus Host.\n",
            " |      \n",
            " |      This method takes as input a string which will be sent as a query to\n",
            " |      the specified Prometheus Host. This query is a PromQL query.\n",
            " |      \n",
            " |      :param query: (str) This is a PromQL query, a few examples can be found\n",
            " |          at https://prometheus.io/docs/prometheus/latest/querying/examples/\n",
            " |      :param start_time: (datetime) A datetime object that specifies the query range start time.\n",
            " |      :param end_time: (datetime) A datetime object that specifies the query range end time.\n",
            " |      :param step: (str) Query resolution step width in duration format or float number of seconds\n",
            " |      :param params: (dict) Optional dictionary containing GET parameters to be\n",
            " |          sent along with the API request, such as \"timeout\"\n",
            " |      :param timeout: (Optional) A timeout (in seconds) applied to the request\n",
            " |      :returns: (dict) A dict of metric data received in response of the query sent\n",
            " |      :raises:\n",
            " |          (RequestException) Raises an exception in case of a connection error\n",
            " |          (PrometheusApiClientException) Raises in case of non 200 response status code\n",
            " |  \n",
            " |  get_current_metric_value(self, metric_name: str, label_config: dict = None, params: dict = None)\n",
            " |      Get the current metric value for the specified metric and label configuration.\n",
            " |      \n",
            " |      :param metric_name: (str) The name of the metric\n",
            " |      :param label_config: (dict) A dictionary that specifies metric labels and their\n",
            " |          values\n",
            " |      :param params: (dict) Optional dictionary containing GET parameters to be sent\n",
            " |          along with the API request, such as \"time\"\n",
            " |      :returns: (list) A list of current metric values for the specified metric\n",
            " |      :raises:\n",
            " |          (RequestException) Raises an exception in case of a connection error\n",
            " |          (PrometheusApiClientException) Raises in case of non 200 response status code\n",
            " |      \n",
            " |      Example Usage:\n",
            " |        .. code-block:: python\n",
            " |      \n",
            " |            prom = PrometheusConnect()\n",
            " |      \n",
            " |            my_label_config = {'cluster': 'my_cluster_id', 'label_2': 'label_2_value'}\n",
            " |      \n",
            " |            prom.get_current_metric_value(metric_name='up', label_config=my_label_config)\n",
            " |  \n",
            " |  get_label_names(self, params: dict = None)\n",
            " |      Get a list of all labels.\n",
            " |      \n",
            " |      :param params: (dict) Optional dictionary containing GET parameters to be\n",
            " |          sent along with the API request, such as \"start\", \"end\" or \"match[]\".\n",
            " |      :returns: (list) A list of labels from the specified prometheus host\n",
            " |      :raises:\n",
            " |          (RequestException) Raises an exception in case of a connection error\n",
            " |          (PrometheusApiClientException) Raises in case of non 200 response status code\n",
            " |  \n",
            " |  get_label_values(self, label_name: str, params: dict = None)\n",
            " |      Get a list of all values for the label.\n",
            " |      \n",
            " |      :param label_name: (str) The name of the label for which you want to get all the values.\n",
            " |      :param params: (dict) Optional dictionary containing GET parameters to be\n",
            " |          sent along with the API request, such as \"time\"\n",
            " |      :returns: (list) A list of names for the label from the specified prometheus host\n",
            " |      :raises:\n",
            " |          (RequestException) Raises an exception in case of a connection error\n",
            " |          (PrometheusApiClientException) Raises in case of non 200 response status code\n",
            " |  \n",
            " |  get_metric_aggregation(self, query: str, operations: list, start_time: datetime.datetime = None, end_time: datetime.datetime = None, step: str = '15', params: dict = None)\n",
            " |      Get aggregations on metric values received from PromQL query.\n",
            " |      \n",
            " |      This method takes as input a string which will be sent as a query to\n",
            " |      the specified Prometheus Host. This query is a PromQL query. And, a\n",
            " |      list of operations to perform such as- sum, max, min, deviation, etc.\n",
            " |      with start_time, end_time and step.\n",
            " |      \n",
            " |      The received query is passed to the custom_query_range method which returns\n",
            " |      the result of the query and the values are extracted from the result.\n",
            " |      \n",
            " |      :param query: (str) This is a PromQL query, a few examples can be found\n",
            " |        at https://prometheus.io/docs/prometheus/latest/querying/examples/\n",
            " |      :param operations: (list) A list of operations to perform on the values.\n",
            " |        Operations are specified in string type.\n",
            " |      :param start_time: (datetime) A datetime object that specifies the query range start time.\n",
            " |      :param end_time: (datetime) A datetime object that specifies the query range end time.\n",
            " |      :param step: (str) Query resolution step width in duration format or float number of seconds\n",
            " |      :param params: (dict) Optional dictionary containing GET parameters to be\n",
            " |        sent along with the API request, such as \"timeout\"\n",
            " |        Available operations - sum, max, min, variance, nth percentile, deviation\n",
            " |        and average.\n",
            " |      \n",
            " |      :returns: (dict) A dict of aggregated values received in response to the operations\n",
            " |        performed on the values for the query sent.\n",
            " |      \n",
            " |      Example output:\n",
            " |        .. code-block:: python\n",
            " |      \n",
            " |          {\n",
            " |              'sum': 18.05674,\n",
            " |              'max': 6.009373\n",
            " |           }\n",
            " |  \n",
            " |  get_metric_range_data(self, metric_name: str, label_config: dict = None, start_time: datetime.datetime = datetime.datetime(2025, 3, 18, 16, 47, 33, 130458), end_time: datetime.datetime = datetime.datetime(2025, 3, 18, 16, 57, 33, 130476), chunk_size: datetime.timedelta = None, store_locally: bool = False, params: dict = None)\n",
            " |      Get the current metric value for the specified metric and label configuration.\n",
            " |      \n",
            " |      :param metric_name: (str) The name of the metric.\n",
            " |      :param label_config: (dict) A dictionary specifying metric labels and their\n",
            " |          values.\n",
            " |      :param start_time:  (datetime) A datetime object that specifies the metric range start time.\n",
            " |      :param end_time: (datetime) A datetime object that specifies the metric range end time.\n",
            " |      :param chunk_size: (timedelta) Duration of metric data downloaded in one request. For\n",
            " |          example, setting it to timedelta(hours=3) will download 3 hours worth of data in each\n",
            " |          request made to the prometheus host\n",
            " |      :param store_locally: (bool) If set to True, will store data locally at,\n",
            " |          `\"./metrics/hostname/metric_date/name_time.json.bz2\"`\n",
            " |      :param params: (dict) Optional dictionary containing GET parameters to be\n",
            " |          sent along with the API request, such as \"time\"\n",
            " |      :return: (list) A list of metric data for the specified metric in the given time\n",
            " |          range\n",
            " |      :raises:\n",
            " |          (RequestException) Raises an exception in case of a connection error\n",
            " |          (PrometheusApiClientException) Raises in case of non 200 response status code\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0uOYnuDgPyeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yt84-4PWPm78"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}